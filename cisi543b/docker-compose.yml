# ref..
# https://gist.github.com/satendra02/1b335b06bfc5921df486f26bd98e0e89
# https://www.reddit.com/r/docker/comments/7zjbe4/docker_rails_puma_nginx_postgres/
# https://itnext.io/docker-rails-puma-nginx-postgres-999cd8866b18

version: "3.6"

networks:
  sister:
    name: sister
  net543b:
    name: net543b

services:

  web:
    build:
      context: .
      dockerfile: ./docker/app.Dockerfile
      args:
        - RACK_ENV=development
        - RAKE_ENV=development
        - RAILS_ENV=development
    working_dir: /app
    restart: unless-stopped
    volumes:
      - ./apprails:/app
      - ~/bundle_cache:/usr/local/bundle/
    # depends_on:
    # - db
    environment:
      - RACK_ENV=development
      - RAKE_ENV=development
      - RAILS_ENV=development
      # - RAILS_LOG_TO_STDOUT=1
      #
      - VIRTUAL_PORT=3000
      - LETSENCRYPT_EMAIL=dgleba@gmail.com
      - VIRTUAL_NETWORK=sister
      - VIRTUAL_HOST=cidev.powderforward.com
      - LETSENCRYPT_HOST=cidev.powderforward.com
    ports:
      - 16123:3000
    networks:
      - sister
      - net543b
    command: bundle exec rails s -p 3000 -b '0.0.0.0'
    #
    # command: bash -c  "bundle check || bundle install --jobs 40 --retry 5 \
    # && bundle exec puma -C config/puma.rb -p 3000  "
    #
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "8"

  dbm:
    image: mysql:5.7
    ports: 
      - 16125:3306
    env_file:
      - .env
    restart: unless-stopped
    volumes:
      # folder for mysql's internal data files.
      # 2020-11-24 change to local mount to keep data more dificult to erase by accident.
      #- mysqldata:/var/lib/mysql
      - ../sysdata/mysql_data:/var/lib/mysql/ 
      # - ../datasys/mysql${PWD}:/var/lib/mysql/  
      #
      # init data scripts..
      - ./mysql-init/:/docker-entrypoint-initdb.d/
      # folder for scripts, etc.
      - ./script:/script
      # folder for exported/imported data, etc.
      - ../data/mydat/:/mydat
    command: --default-authentication-plugin=mysql_native_password
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "6"
    healthcheck:
      test: ["CMD", ping", "-c 2", "localhost"]
      interval: 1m30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - net543b

  adr:
    # 10.4.1.231:6117/
    image: adminer:4.7
    restart: always
    ports:
      - 16126:8080
    environment:
      - ADMINER_DEFAULT_SERVER=dbm
      # - ADMINER_PLUGINS='tables-filter tinymce'
      #
      - VIRTUAL_PORT=8000
      - LETSENCRYPT_EMAIL=dgleba@stackpole.com
      - VIRTUAL_NETWORK=sister    
      # - VIRTUAL_HOST=cisi2adr.dg.ab3w.com
      # - LETSENCRYPT_HOST=cisi2adr.dg.ab3w.com
      # - VIRTUAL_HOST=adr-104-129-128-216.nip.io
      # - LETSENCRYPT_HOST=adr-104-129-128-216.nip.io
      #
      # - VIRTUAL_HOST=adr-104-129-128-216.cloud-xip.io
      # - LETSENCRYPT_HOST=adr-104-129-128-216.cloud-xip.io
      - VIRTUAL_HOST=adr.powderforward.com
      - LETSENCRYPT_HOST=adr.powderforward.com
    networks:
      - net543b
      - sister

  # adrl:
  #   # 10.4.1.231:6117/
  #   # image: adminer:4.7
  #   # image: dockette/adminer:full
  #   image: dgleba/adminer-sqlite:one
  #   # build: ./adminer-sqlite    
  #   restart: always
  #   ports:
  #     - 16124:80
  #     # 8080 for regular adminer, 80 for dockette
  #   volumes:
  #     - ./apprails/db/development.sqlite3:/db.sq3
  #     - ./adminer-sqlite:/var/www/html
  #   environment:
  #     - ADMINER_DEFAULT_SERVER=s
  #     - DB_PATH=/db.sq3
  #     - DB_USER=u 
  #     - DB_PASS=a
  #     # - ADMINER_PLUGINS='tables-filter'
  #   networks:
  #     - sister


  jproxy:
  # docker-compose pull nproxy to update...
    image: jwilder/nginx-proxy:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./vol/nginx/certs:/etc/nginx/certs:ro
      - ./vol/nginx/html:/usr/share/nginx/html
      - ./vol/nginx/vhost.d:/etc/nginx/vhost.d:ro
      # dgleba add hardening by using this enhanced config.
      - ./docker/jproxy/nginxhard.conf:/etc/nginx/nginx.conf
      # - ./vol/nginx/conf.d:/etc/nginx/conf.d/
      # if need be add this file with your global settings..
      # - ./vol/nginx/conf.d/my_proxy.conf:/etc/nginx/conf.d/my_proxy.conf:ro
    labels:
      com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy: "true"
    restart: always
    networks:
      - sister
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "7"

  lets:
    image: jrcs/letsencrypt-nginx-proxy-companion:v1.13.1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./vol/nginx/vhost.d:/etc/nginx/vhost.d
      - ./vol/nginx/certs:/etc/nginx/certs:rw
      - ./vol/nginx/html:/usr/share/nginx/html
    restart: always
    networks:
      - sister
    depends_on:
      - jproxy
    # links will share the volumes between containers.
    links:
      - jproxy
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "8"


  # h.powderforward.com
  home:
    # 192.168.88.60:6216
    image: nginx:1.19-alpine
    ports:
      - "6219:8083"
    expose:
      - "8083"
    volumes:
      # - ./docker/nginx_h/nginxmain.conf:/etc/nginx/nginx.conf
      # - ./docker/nginx_h/default.conf:/etc/nginx/conf.d/default.conf
      - ./homepage:/usr/share/nginx/html
    restart: always
    networks:
      - sister
    environment:
      - VIRTUAL_HOST=powderforward.com
      - LETSENCRYPT_HOST=powderforward.com
      - VIRTUAL_PORT=8083
      - LETSENCRYPT_EMAIL=dgleba@stackpole.com
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

volumes:
  mysqldata:
  